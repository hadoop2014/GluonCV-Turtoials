{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare COCO datasets\n==============================\n\n`COCO <http://cocodataset.org/#home>`_ is a large-scale object detection, segmentation, and captioning datasetself.\nThis tutorial will walk through the steps of preparing this dataset for GluonCV.\n\n![](http://cocodataset.org/images/coco-logo.png)\n\n\n.. hint::\n\n   You need 42.7 GB disk space to download and extract this dataset. SSD is\n   preferred over HDD because of its better performance.\n\n   The total time to prepare the dataset depends on your Internet speed and disk\n   performance. For example, it often takes 20 min on AWS EC2 with EBS.\n\nPrepare the dataset\n-------------------\n\nWe need the following four files from `COCO <http://cocodataset.org/#download>`_:\n\n+------------------------------------------------------------------------------------------------------------------------+--------+------------------------------------------+\n| Filename                                                                                                               | Size   | SHA-1                                    |\n+========================================================================================================================+========+==========================================+\n| `train2017.zip <http://images.cocodataset.org/zips/train2017.zip>`_                                                    | 18 GB  | 10ad623668ab00c62c096f0ed636d6aff41faca5 |\n+------------------------------------------------------------------------------------------------------------------------+--------+------------------------------------------+\n| `val2017.zip <http://images.cocodataset.org/zips/val2017.zip>`_                                                        | 778 MB | 4950dc9d00dbe1c933ee0170f5797584351d2a41 |\n+------------------------------------------------------------------------------------------------------------------------+--------+------------------------------------------+\n| `annotations_trainval2017.zip  <http://images.cocodataset.org/annotations/annotations_trainval2017.zip>`_              | 241 MB | 8551ee4bb5860311e79dace7e79cb91e432e78b3 |\n+------------------------------------------------------------------------------------------------------------------------+--------+------------------------------------------+\n| `stuff_annotations_trainval2017.zip <http://images.cocodataset.org/annotations/stuff_annotations_trainval2017.zip>`_   | 401 MB | e7aa0f7515c07e23873a9f71d9095b06bcea3e12 |\n+------------------------------------------------------------------------------------------------------------------------+--------+------------------------------------------+\n\nThe easiest way to download and unpack these files is to download helper script\n:download:`mscoco.py<../../../scripts/datasets/mscoco.py>` and run\nthe following command:\n\n.. code-block:: bash\n\n    python mscoco.py\n\nwhich will automatically download and extract the data into ``~/.mxnet/datasets/coco``.\n\nIf you already have the above files sitting on your disk,\nyou can set ``--download-dir`` to point to them.\nFor example, assuming the files are saved in ``~/coco/``, you can run:\n\n.. code-block:: bash\n\n   python mscoco.py --download-dir ~/coco\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read with GluonCV\n-----------------\n\nLoading images and labels is straight-forward with\n:py:class:`gluoncv.data.COCODetection`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gluoncv import data, utils\nfrom matplotlib import pyplot as plt\n\ntrain_dataset = data.COCODetection(splits=['instances_train2017'])\nval_dataset = data.COCODetection(splits=['instances_val2017'])\nprint('Num of training images:', len(train_dataset))\nprint('Num of validation images:', len(val_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's visualize one example.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_image, train_label = train_dataset[0]\nbounding_boxes = train_label[:, :4]\nclass_ids = train_label[:, 4:5]\nprint('Image size (height, width, RGB):', train_image.shape)\nprint('Num of objects:', bounding_boxes.shape[0])\nprint('Bounding boxes (num_boxes, x_min, y_min, x_max, y_max):\\n',\n      bounding_boxes)\nprint('Class IDs (num_boxes, ):\\n', class_ids)\n\nutils.viz.plot_bbox(train_image.asnumpy(), bounding_boxes, scores=None,\n                    labels=class_ids, class_names=train_dataset.classes)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, to use both ``train_dataset`` and ``val_dataset`` for training, we\ncan pass them through data transformations and load with\n:py:class:`mxnet.gluon.data.DataLoader`, see :download:`train_ssd.py\n<../../../scripts/detection/ssd/train_ssd.py>` for more information.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}