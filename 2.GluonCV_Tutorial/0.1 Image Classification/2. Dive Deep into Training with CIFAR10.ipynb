{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Dive Deep into Training with CIFAR10\n==============================================\n\nHope you enjoyed playing with our demo script.\nNow, you may be wandering: how exactly was the model trained?\nIn this tutorial, we will focus on answering this question.\n\nPrerequisites\n-------------\n\nWe assume readers have a basic understanding of ``Gluon``.\nIf not, we suggest you spend 60 minutes to get started with the `Gluon Crash\nCourse <http://gluon-crash-course.mxnet.io/index.html>`__ .\n\nAs we all know, training deep neural networks on GPUs is way faster than\ntraining on CPU.\nIn the previous tutorials, we used CPU because classifying a single image is a\nrelatively easy task.\nHowever, since we are about to train a model, it is strongly recommended to\nuse a machine with GPU(s).\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The rest of the tutorial walks you through the details of ``CIFAR10`` training.\n    If you want a quick start without knowing the details, try downloading\n    this script and start training with just one command.\n\n    :download:`Download train_cifar10.py<../../../scripts/classification/cifar/train_cifar10.py>`\n\n    Here's a sample command with recommended parameters:\n\n    ::\n\n        python train_cifar10.py --num-epochs 240 --mode hybrid --num-gpus 1 -j 8 --batch-size 128            --wd 0.0001 --lr 0.1 --lr-decay 0.1 --lr-decay-epoch 80,160 --model cifar_resnet20_v1</p></div>\n\n\nNetwork Structure\n-----------------\n\nFirst, let's import the necessary libraries into python.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import division\n\nimport argparse, time, logging, random, math\n\nimport numpy as np\nimport mxnet as mx\n\nfrom mxnet import gluon, nd\nfrom mxnet import autograd as ag\nfrom mxnet.gluon import nn\nfrom mxnet.gluon.data.vision import transforms\n\nfrom gluoncv.model_zoo import get_model\nfrom gluoncv.utils import makedirs, TrainingHistory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are numerous structures for convolutional neural networks.\nHere we pick a simple yet well-performing structure, ``cifar_resnet20_v1``, for the\ntutorial.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# number of GPUs to use\nnum_gpus = 1\nctx = [mx.gpu(i) for i in range(num_gpus)]\n\n# Get the model CIFAR_ResNet20_v1, with 10 output classes, without pre-trained weights\nnet = get_model('cifar_resnet20_v1', classes=10)\nnet.initialize(mx.init.Xavier(), ctx = ctx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data Augmentation and Data Loader\n---------------------------------\n\nData augmentation is a common technique used for training. It is\nbase on the assumption that, for the same object, photos under different\ncomposition, lighting condition, or color should all yield the same prediction.\n\nHere are photos of the Golden Bridge, taken by many people,\nat different time from different angles.\nWe can easily tell that they are photos of the same thing.\n\n|image-golden-bridge|\n\nWe want to teach this invariance to our model, by playing \"augmenting\"\ninput image. Our augmentation transforms the image with\nresizing, cropping, flipping and other techniques.\n\nWith ``Gluon``, we can create our transform function as following:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "transform_train = transforms.Compose([\n    # Randomly crop an area, and then resize it to be 32x32\n    transforms.RandomResizedCrop(32),\n    # Randomly flip the image horizontally\n    transforms.RandomFlipLeftRight(),\n    # Randomly jitter the brightness, contrast and saturation of the image\n    transforms.RandomColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n    # Randomly adding noise to the image\n    transforms.RandomLighting(0.1),\n    # Transpose the image from height*width*num_channels to num_channels*height*width\n    # and map values from [0, 255] to [0,1]\n    transforms.ToTensor(),\n    # Normalize the image with mean and standard deviation calculated across all images\n    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You may have noticed that most of the operations are randomized. This in effect\nincreases the number of different images the model sees during training.\nThe more data we have, the better our model generalizes over\nunseen images.\n\nOn the other hand, when making prediction, we would like to remove all\nrandom operations in order to get a deterministic result. The transform\nfunction for prediction is:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "transform_test = transforms.Compose([\n    transforms.Resize(32),\n    transforms.ToTensor(),\n    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that it is important to keep the normalization step, since the\nmodel only works well on inputs from the same distribution.\n\nWith the transform functions, we can define data loaders for our\ntraining and validation datasets.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Batch Size for Each GPU\nper_device_batch_size = 128\n# Number of data loader workers\nnum_workers = 8\n# Calculate effective total batch size\nbatch_size = per_device_batch_size * num_gpus\n\n# Set train=True for training data\n# Set shuffle=True to shuffle the training data\ntrain_data = gluon.data.DataLoader(\n    gluon.data.vision.CIFAR10(train=True).transform_first(transform_train),\n    batch_size=batch_size, shuffle=True, last_batch='discard', num_workers=num_workers)\n\n# Set train=False for validation data\nval_data = gluon.data.DataLoader(\n    gluon.data.vision.CIFAR10(train=False).transform_first(transform_test),\n    batch_size=batch_size, shuffle=False, num_workers=num_workers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Optimizer, Loss and Metric\n--------------------------\n\nOptimizer improves the model during training. Here we use the popular\nNesterov accelerated gradient descent algorithm.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Learning rate decay factor\nlr_decay = 0.1\n# Epochs where learning rate decays\nlr_decay_epoch = [80, 160, np.inf]\n\n# Nesterov accelerated gradient descent\noptimizer = 'nag'\n# Set parameters\noptimizer_params = {'learning_rate': 0.1, 'wd': 0.0001, 'momentum': 0.9}\n\n# Define our trainer for net\ntrainer = gluon.Trainer(net.collect_params(), optimizer, optimizer_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the above code, ``lr_decay`` and ``lr_decay_epoch`` are not directly\nused in ``trainer``. One important idea in model training is to\ngradually decrease learning rate. This means the optimizer takes large\nsteps at the beginning, but step size becomes smaller and smaller in time.\n\nOur plan sets the learning rate to 0.1 at the beginning, then\ndivide it by 10 at the 80-th epoch, then again at the 160-th epoch.\nWe'll use `lr_decay_epoch` in the main training loop for this purpose.\n\nIn order to optimize our model, we need a loss function.\nIn essence, loss functions compute the difference between predictions and the\nground-truth as a measure of model performance.\nWe can then take the gradients of the loss w.r.t. the weights.\nGradients points the optimizer to the direction weights should move to\nimprove model performance.\n\nFor classification tasks, we usually use softmax cross entropy as the\nloss function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "loss_fn = gluon.loss.SoftmaxCrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Metrics are similar to loss functions, but they are different in the\nfollowing aspects:\n\n-  Metric is how we evaluate model performance. Each metric is related to a\n   specific task, but independent from the model training process.\n-  For classification, we usually only use one loss function to train\n   our model, but we can have several metrics for evaluating\n   performance.\n-  Loss function can be used as a metric, but sometimes its values are hard\n   to interpretate. For instance, the concept \"accuracy\" is\n   easier to understand than \"softmax cross entropy\"\n\nFor simplicity, we use accuracy as the metric to monitor our training\nprocess. Besides, we record metric values, and will print them at the\nend of training.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_metric = mx.metric.Accuracy()\ntrain_history = TrainingHistory(['training-error', 'validation-error'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Validation\n----------\n\nValidation dataset provides us a way of monitoring the training process.\nWe have labels for validation data, but they are held out during training.\nInstead, we use them to evaluate the models performance on unseen data\nand prevent overfitting.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def test(ctx, val_data):\n    metric = mx.metric.Accuracy()\n    for i, batch in enumerate(val_data):\n        data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n        label = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\n        outputs = [net(X) for X in data]\n        metric.update(label, outputs)\n    return metric.get()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to evaluate performance, we need a metric. Then, we loop\nthrough the validation data and predict with our model.\nWe'll run this function at the end of every epoch to show improvement.\nover the last epoch.\n\nTraining\n--------\n\nAfter all the preparations, we can finally start training!\nFollowing is the script.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>In order to finish the tutorial quickly, we only train for 3 epochs.\n  In your experiments, we recommend setting ``epochs=240``.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "epochs = 3\nlr_decay_count = 0\n\nfor epoch in range(epochs):\n    tic = time.time()\n    train_metric.reset()\n    train_loss = 0\n\n    # Learning rate decay\n    if epoch == lr_decay_epoch[lr_decay_count]:\n        trainer.set_learning_rate(trainer.learning_rate*lr_decay)\n        lr_decay_count += 1\n\n    # Loop through each batch of training data\n    for i, batch in enumerate(train_data):\n        # Extract data and label\n        data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n        label = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\n\n        # AutoGrad\n        with ag.record():\n            output = [net(X) for X in data]\n            loss = [loss_fn(yhat, y) for yhat, y in zip(output, label)]\n\n        # Backpropagation\n        for l in loss:\n            l.backward()\n\n        # Optimize\n        trainer.step(batch_size)\n\n        # Update metrics\n        train_loss += sum([l.sum().asscalar() for l in loss])\n        train_metric.update(label, output)\n\n    name, acc = train_metric.get()\n    # Evaluate on Validation data\n    name, val_acc = test(ctx, val_data)\n\n    # Update history and print metrics\n    train_history.update([1-acc, 1-val_acc])\n    print('[Epoch %d] train=%f val=%f loss=%f time: %f' %\n        (epoch, acc, val_acc, train_loss, time.time()-tic))\n\n# We can plot the metric scores with:\n\ntrain_history.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you trained the model for 240 epochs, the plot may look like:\n\n|image-aug|\n\nWe can better observe the process of model training with plots.\nFor example, one may ask what will happen if there's no data augmentation:\n\n|image-no-aug|\n\nWe can see that training error is much lower than validation error.\nAfter the model reaches 100\\% accuracy on training data,\nit stops improving on validation data.\nThese two plots evidently demonstrates the importance of data augmentation.\n\nModel Saving and Loading\n------------------------\n\nAfter training, we usually want to save it for later use.\nThis is simply done with:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "net.save_parameters('dive_deep_cifar10_resnet20_v2.params')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next time if you need to use it, just run\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "net.load_parameters('dive_deep_cifar10_resnet20_v2.params', ctx=ctx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next Step\n---------\n\nThis is the end of our adventure with ``CIFAR10``, but there are many\nmore datasets and algorithms in computer vision!\n\nIf you would like to know how to train a model on a much larger dataset\nthan ``CIFAR10``, e.g. ImageNet, please read `ImageNet Training <dive_deep_imagenet.html>`__.\n\nOr, if you want like to know what can be done with the model you just\ntrained, please read the tutorial on `Transfer learning <transfer_learning_minc.html>`__.\n\n.. |image-no-aug| image:: https://raw.githubusercontent.com/dmlc/web-data/master/gluoncv/classification/overfitting.png\n.. |image-aug| image:: https://raw.githubusercontent.com/dmlc/web-data/master/gluoncv/classification/normal_training.png\n.. |image-golden-bridge| image:: https://raw.githubusercontent.com/dmlc/web-data/master/gluoncv/classification/golden-bridge.png\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}